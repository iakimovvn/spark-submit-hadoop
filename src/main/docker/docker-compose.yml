version: '3.7'
x-extra_hosts:
  &default-extra_hosts
  - "krb5.df.cluster:172.29.0.10"
  - "hdfs-nn.df.cluster:172.29.0.4"
  - "hdfs-dn.df.cluster:172.29.0.5"
  - "hive-server.df.cluster:172.29.0.8"
  - "hive-metastore.df.cluster:172.29.0.9"
  - "hive-metastore-db.df.cluster:172.29.0.19"
  - "spark-submit.df.cluster:172.29.0.11"
  - "spark-master.df.cluster:172.29.0.12"
  - "spark-worker-1.df.cluster:172.29.0.13"
  - "spark-worker-2.df.cluster:172.29.0.14"
  - "nodemanager.df.cluster:172.29.0.20"
  - "resourcemanager.df.cluster:172.29.0.21"
  - "historyserver.df.cluster:172.29.0.22"
services:
  krb5-server:
    image: krb5:0.1
    container_name: krb5
    hostname: krb5.df.cluster
    extra_hosts: *default-extra_hosts
    privileged: true
    tty: true
    stdin_open: true
    networks:
      cl-net:
        ipv4_address: 172.29.0.10
  hdfs-nn:
    image: hadoop-namenode:3.1.2
    container_name: hdfs-nn
    hostname: hdfs-nn.df.cluster
    extra_hosts: *default-extra_hosts
    privileged: true
    ports:
      - "5045:5005"
    tty: true
    stdin_open: true
    depends_on:
      - krb5-server
    environment:
      - JAVA_OPTS=-Xms128m -Xmx256m -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005
      - HDFS_CONF_dfs_webhdfs_enabled=false
    networks:
      cl-net:
        ipv4_address: 172.29.0.4
    command: sh -c "wait-for-it.sh krb5.df.cluster:22 -- run.sh && tail -f /opt/hadoop-3.1.2/logs/hadoop.log"
  hdfs-dn:
    image: hadoop-datanode:3.1.2
    container_name: hdfs-dn
    hostname: hdfs-dn.df.cluster
    extra_hosts: *default-extra_hosts
    privileged: true
    ports:
      - "5055:5005"
    tty: true
    stdin_open: true
    depends_on:
      - hdfs-nn
    environment:
      - JAVA_OPTS=-Xms128m -Xmx256m -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 -Dio.file.buffer.size=65536
    networks:
      cl-net:
        ipv4_address: 172.29.0.5
    command: sh -c "wait-for-it.sh krb5.df.cluster:22 -- run.sh && tail -f /opt/hadoop-3.1.2/logs/hadoop.log"
  hive-server:
    image: hadoop-hive:2.3.7
    hostname: hive-server.df.cluster
    container_name: hive-server
    extra_hosts: *default-extra_hosts
    depends_on:
      - krb5-server
      - hive-metastore
    privileged: true
    tty: true
    stdin_open: true
    command: "wait-for-it.sh hdfs-nn.df.cluster:8020 -- /usr/local/bin/run.sh hiveserver2"
    ports:
      - "5155:5005"
    env_file:
      - ./hadoop/hive/hive.env
    environment:
      SERVICE_PRECONDITION: "hive-metastore.df.cluster:9083"
    networks:
      cl-net:
        ipv4_address: 172.29.0.8
  hive-metastore:
    image: hadoop-hive:2.3.7
    hostname: hive-metastore.df.cluster
    container_name: hive-metastore
    extra_hosts: *default-extra_hosts
    depends_on:
      - krb5-server
    privileged: true
    tty: true
    stdin_open: true
    command: "wait-for-it.sh hdfs-nn.df.cluster:8020 -- /usr/local/bin/run.sh hivemetastore"
    ports:
      - "5105:5005"
    env_file:
      - ./hadoop/hive/hive.env
    environment:
      SERVICE_PRECONDITION: "hive-metastore-db.df.cluster:5432"
    networks:
      cl-net:
        ipv4_address: 172.29.0.9
  hive-metastore-db:
    image: bde2020/hive-metastore-postgresql:2.3.0
    hostname: hive-metastore-db.df.cluster
    container_name: hive-metastore-db
    ports:
      - "5433:5432"
    extra_hosts: *default-extra_hosts
    privileged: true
    tty: true
    stdin_open: true
    networks:
      cl-net:
        ipv4_address: 172.29.0.19
  nodemanager:
    image: hadoop-nodemanager:3.1.2
    hostname: nodemanager.df.cluster
    container_name: nodemanager
    extra_hosts: *default-extra_hosts
    depends_on:
      - krb5-server
    privileged: true
    tty: true
    stdin_open: true
    command: "wait-for-it.sh krb5.df.cluster:22 -- /usr/local/bin/run.sh"
    env_file:
      - ./hadoop/hive/hive.env
    networks:
      cl-net:
        ipv4_address: 172.29.0.20
    ports:
      - "8042:8042"
  resourcemanager:
    image: hadoop-resourcemanager:3.1.2
    hostname: resourcemanager.df.cluster
    container_name: resourcemanager
    extra_hosts: *default-extra_hosts
    restart: always
    depends_on:
      - krb5-server
    privileged: true
    tty: true
    stdin_open: true
    command: "wait-for-it.sh hdfs-dn.df.cluster:50010 --  -- /usr/local/bin/run.sh"
    env_file:
      - ./hadoop/hive/hive.env
    ports:
      - "8088:8088"
    networks:
      cl-net:
        ipv4_address: 172.29.0.21
  historyserver:
    image: hadoop-historyserver:3.1.2
    hostname: historyserver.df.cluster
    container_name: historyserver
    extra_hosts: *default-extra_hosts
    depends_on:
      - krb5-server
    privileged: true
    tty: true
    stdin_open: true
    env_file:
      - ./hadoop/hive/hive.env
    ports:
      - "8188:8188"
    command: sh -c "wait-for-it.sh krb5.df.cluster:22 -- /usr/local/bin/run.sh"
    networks:
      cl-net:
        ipv4_address: 172.29.0.22
  spark-master:
    image: hadoop-spark:2.3.0
    hostname: spark-master.df.cluster
    container_name: spark-master
    extra_hosts: *default-extra_hosts
    privileged: true
    tty: true
    stdin_open: true
    depends_on:
      - krb5-server
    command: start-master
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
      - "5105:5005"
    environment:
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_MASTER_LOG=/spark/logs
      - SPARK_MASTER=spark-master.df.cluster:7077
      - SPARK_JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005
    networks:
      cl-net:
        ipv4_address: 172.29.0.12
  spark-submit:
    image: spark-submit:3.1.1
    hostname: spark-submit.df.cluster
    container_name: spark-submit
    extra_hosts: *default-extra_hosts
    privileged: true
    tty: true
    stdin_open: true
    depends_on:
      - krb5-server
    command: sh -c "/usr/local/bin/run.sh"
    networks:
      cl-net:
        ipv4_address: 172.29.0.11

networks:
  cl-net:
    ipam:
      driver: default
      config:
        - subnet: 172.29.0.0/16